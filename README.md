# FitTÃ¼rkAI RAG Sistemi - CPU Optimize Linux Versiyonu

ğŸ‹ï¸ **FitTÃ¼rkAI**, TÃ¼rkÃ§e fitness ve saÄŸlÄ±k danÄ±ÅŸmanlÄ±ÄŸÄ± iÃ§in geliÅŸtirilmiÅŸ Retrieval-Augmented Generation (RAG) sistemidir. Bu versiyon **CPU kullanÄ±mÄ± iÃ§in optimize edilmiÅŸtir** ve **Google Colab** gibi Linux ortamlarÄ±nda sorunsuz Ã§alÄ±ÅŸÄ±r.

## ğŸš€ Ã–zellikler

- **CPU Optimize EdilmiÅŸ**: GPU gerektirmez, CPU'da verimli Ã§alÄ±ÅŸÄ±r
- **TÃ¼rkÃ§e Dil DesteÄŸi**: TÃ¼rkÃ§e dokÃ¼manlarÄ± iÅŸler ve yanÄ±tlar
- **RAG Sistemi**: PDF ve JSON belgelerinden bilgi Ã§Ä±karÄ±r ve kullanÄ±r
- **Interactive Chat**: GerÃ§ek zamanlÄ± soru-cevap sistemi
- **LoRA Adapter DesteÄŸi**: Fine-tune edilmiÅŸ modelleri destekler
- **Linux Uyumlu**: Google Colab, Ubuntu, ve diÄŸer Linux daÄŸÄ±tÄ±mlarÄ±nda Ã§alÄ±ÅŸÄ±r

## ğŸ“‹ Sistem Gereksinimleri

### Minimum Gereksinimler
- **RAM**: En az 4 GB (8 GB Ã¶nerilir)
- **Disk**: 5 GB boÅŸ alan
- **Ä°ÅŸletim Sistemi**: Linux (Ubuntu, Google Colab vb.)
- **Python**: 3.8 veya Ã¼zeri

### Google Colab Ä°Ã§in
- Ãœcretsiz Google Colab hesabÄ± yeterlidir
- GPU gerekmez (CPU modunda Ã§alÄ±ÅŸÄ±r)

## ğŸ› ï¸ Kurulum

### 1. Google Colab'da HÄ±zlÄ± Kurulum

```python
# Google Colab'da yeni bir notebook oluÅŸturun ve ÅŸunu Ã§alÄ±ÅŸtÄ±rÄ±n:

# 1. Repository'yi klonlayÄ±n
!git clone https://github.com/YOUR_USERNAME/FitTurkAI-RAG.git
%cd FitTurkAI-RAG

# 2. Otomatik kurulum scriptini Ã§alÄ±ÅŸtÄ±rÄ±n
!python colab_setup_and_run.py
```

### 2. Manuel Kurulum

```bash
# 1. Repository'yi klonlayÄ±n
git clone https://github.com/YOUR_USERNAME/FitTurkAI-RAG.git
cd FitTurkAI-RAG

# 2. Python sanal ortamÄ± oluÅŸturun (opsiyonel)
python -m venv venv
source venv/bin/activate  # Linux/Mac

# 3. Gerekli paketleri yÃ¼kleyin
pip install -r requirements.txt

# 4. NLTK verilerini indirin
python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords')"
```

## ğŸ“ KlasÃ¶r YapÄ±sÄ±

```
FitTurkAI-RAG/
â”œâ”€â”€ test.py                    # Ana RAG sistemi (CPU optimize)
â”œâ”€â”€ colab_setup_and_run.py     # Google Colab kurulum scripti
â”œâ”€â”€ requirements.txt           # CPU iÃ§in paket listesi
â”œâ”€â”€ README.md                  # Bu dosya
â”œâ”€â”€ indirilen_pdfler/          # PDF dosyalarÄ±nÄ±z (oluÅŸturulacak)
â”œâ”€â”€ DATA/                      # JSON veri dosyalarÄ±nÄ±z (oluÅŸturulacak)
â”œâ”€â”€ fitness_rag_store_merged/  # Vector store (oluÅŸturulacak)
â””â”€â”€ fine_tuned_FitTurkAI_QLoRA/ # LoRA adapter (opsiyonel)
```

## ğŸš´â€â™€ï¸ KullanÄ±m

### 1. Temel KullanÄ±m

```python
# Ana scripti Ã§alÄ±ÅŸtÄ±rÄ±n
python test.py
```

### 2. Google Colab'da Programmatik KullanÄ±m

```python
from test import FitnessRAG, RAGConfig

# KonfigÃ¼rasyon oluÅŸturun
config = RAGConfig(
    peft_model_path=None  # Base model kullanmak iÃ§in None yapÄ±n
)

# RAG sistemini baÅŸlatÄ±n
rag_system = FitnessRAG(config)

# Bilgi tabanÄ±nÄ± oluÅŸturun (ilk Ã§alÄ±ÅŸtÄ±rmada)
rag_system.build_knowledge_base(
    pdf_dir="./indirilen_pdfler",
    json_dir="./DATA"
)

# Soru sorun
answer = rag_system.ask("SaÄŸlÄ±klÄ± kahvaltÄ± iÃ§in ne Ã¶nerirsiniz?")
print(answer)

# Interactive mode baÅŸlatÄ±n
rag_system.interactive_chat()
```

### 3. Veri Ekleme

#### PDF DosyalarÄ±
```bash
# PDF'lerinizi bu klasÃ¶re koyun
cp your_fitness_pdfs/*.pdf ./indirilen_pdfler/
```

#### JSON Verileri
```python
# Ã–rnek JSON formatÄ±
{
  "soru": "Egzersiz Ã¶ncesi ne yemeli?",
  "cevap": "Egzersiz Ã¶ncesi hafif, karbonhidrat aÄŸÄ±rlÄ±klÄ± besinler tercih edin..."
}
```

## âš™ï¸ KonfigÃ¼rasyon

`RAGConfig` sÄ±nÄ±fÄ±nda Ã¶zelleÅŸtirilebilir parametreler:

```python
config = RAGConfig(
    # Veri parametreleri
    chunk_size=300,                    # Kelime baÅŸÄ±na chunk boyutu
    chunk_overlap_sentences=2,         # Overlap cÃ¼mle sayÄ±sÄ±
    retrieval_k=5,                     # KaÃ§ belge getirilecek
    
    # Model parametreleri
    generator_model_name="ytu-ce-cosmos/Turkish-Llama-8b-v0.1",
    peft_model_path=None,              # LoRA adapter yolu
    
    # Performans parametreleri
    max_context_length=3000            # Maksimum context uzunluÄŸu
)
```

## ğŸ”§ Sorun Giderme

### YaygÄ±n Sorunlar

#### 1. Bellek HatasÄ± (OOM)
```python
# Chunk boyutunu kÃ¼Ã§Ã¼ltÃ¼n
config = RAGConfig(chunk_size=200, max_context_length=2000)
```

#### 2. Model YÃ¼kleme HatasÄ±
```python
# Base model kullanÄ±n (LoRA olmadan)
config = RAGConfig(peft_model_path=None)
```

#### 3. NLTK Veri HatasÄ±
```python
import nltk
nltk.download('punkt_tab')  # Yeni NLTK sÃ¼rÃ¼mÃ¼ iÃ§in
nltk.download('punkt')      # Eski NLTK sÃ¼rÃ¼mÃ¼ iÃ§in
nltk.download('stopwords')
```

### Google Colab Ã–zel Ã‡Ã¶zÃ¼mler

#### GPU'yu KapatÄ±n
```python
import os
os.environ['CUDA_VISIBLE_DEVICES'] = ''  # GPU'yu devre dÄ±ÅŸÄ± bÄ±rak
```

#### Bellek Optimizasyonu
```python
# BÃ¼yÃ¼k modeller iÃ§in
import torch
torch.set_num_threads(2)  # CPU thread sayÄ±sÄ±nÄ± sÄ±nÄ±rla
```

## ğŸ“Š Performans OptimizasyonlarÄ±

### CPU Ä°Ã§in Ä°puÃ§larÄ±

1. **Model Boyutu**: Daha kÃ¼Ã§Ã¼k embedding modelleri kullanÄ±n
2. **Chunk Size**: Daha kÃ¼Ã§Ã¼k chunk'lar daha hÄ±zlÄ±dÄ±r
3. **Thread SayÄ±sÄ±**: CPU Ã§ekirdek sayÄ±nÄ±za gÃ¶re ayarlayÄ±n
4. **Batch Size**: Tek seferde iÅŸlenecek belge sayÄ±sÄ±nÄ± sÄ±nÄ±rlayÄ±n

```python
# HÄ±zlÄ± konfigÃ¼rasyon
fast_config = RAGConfig(
    embedding_model_name="paraphrase-multilingual-MiniLM-L6-v2",  # Daha kÃ¼Ã§Ã¼k
    chunk_size=200,
    retrieval_k=3,
    max_context_length=2000
)
```

## ğŸ¤ KatkÄ±da Bulunma

1. Fork edin
2. Feature branch oluÅŸturun (`git checkout -b feature/AmazingFeature`)
3. Commit yapÄ±n (`git commit -m 'Add some AmazingFeature'`)
4. Push edin (`git push origin feature/AmazingFeature`)
5. Pull Request aÃ§Ä±n

## ğŸ“ DeÄŸiÅŸiklik NotlarÄ±

### v2.0 - CPU Optimized
- âœ… GPU baÄŸÄ±mlÄ±lÄ±ÄŸÄ± kaldÄ±rÄ±ldÄ±
- âœ… CPU iÃ§in optimize edildi
- âœ… Google Colab desteÄŸi eklendi
- âœ… Otomatik kurulum scripti eklendi
- âœ… Bellek optimizasyonlarÄ±

### v1.0 - GPU Version
- âš ï¸ Bu versiyon GPU gerektiriyordu (deprecated)

## ğŸ“ Destek

- **Issues**: GitHub Issues bÃ¶lÃ¼mÃ¼nÃ¼ kullanÄ±n
- **Discussions**: Genel sorular iÃ§in GitHub Discussions
- **Email**: [your-email@domain.com]

## ğŸ“„ Lisans

Bu proje MIT lisansÄ± altÄ±nda lisanslanmÄ±ÅŸtÄ±r - detaylar iÃ§in [LICENSE](LICENSE) dosyasÄ±na bakÄ±n.

## ğŸ™ TeÅŸekkÃ¼rler

- Hugging Face Transformers ekibine
- Turkish LLaMA projesine
- Sentence Transformers ekibine
- FAISS ekibine

---

â­ **Bu projeyi beÄŸendiyseniz, lÃ¼tfen yÄ±ldÄ±zlamayÄ± unutmayÄ±n!** 